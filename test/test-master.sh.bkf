docker run -dit \
-e MASTER="nvdl-bsg-d000" \
-e SPARK_WORKER_CORES=`nproc` \
-e SPARK_WORKER_OPTS='-Dspark.worker.resource.gpu.amount=1 -Dspark.worker.resource.gpu.discoveryScript=/mnt/nvdl/datasets/tpcds/sparkRapidsPlugin/getGpusResources.sh' \
-e CONCURRENTGPU=2 \
-e TOTAL_CORES="24" \
-e NUM_EXECUTORS="2" \
-e NUM_EXECUTOR_CORES="12" \
-e EXECUTOR_MEMORY="16277M" \
-e PINNED_POOL_SIZE="2034M" \
-e DRIVER_MEMORY="10240M" \
-e SHUFFLE_PARTITIONS=64 \
-e MAXPARTITIONBYTES="256M" \
-e SPILL_STORAGE_SIZE="2048M" \
-e OUTPUT_PATH="file:///mnt/nvdl/datasets/tpcds/output" \
-e INPUT_PATH="file:///mnt/nvdl/datasets/tpcds/input/useDecimal=false,useDate=true,filterNull=false" \
-e INPUT_FORMAT="parquet" \
-e OUTPUT_FORMAT="parquet" \
-e SPARK_RAPIDS_PLUGIN_JAR="/mnt/nvdl/datasets/tpcds/sparkRapidsPlugin/rapids-4-spark_2.12-0.4.0-20210112.085853-45.jar" \
-e SPARK_RAPIDS_PLUGIN_INTEGRATION_TEST_JAR="/mnt/nvdl/datasets/tpcds/tpcds/rapids-4-spark-integration-tests_2.12-0.4.0-20210112.090812-45-jar-with-dependencies.jar" \
-e SPARK_CUDF_JAR="/mnt/nvdl/datasets/tpcds/sparkRapidsPlugin/cudf-0.18-20210112.093909-33-cuda11.jar" \
-e BENCHMARK="tpcds" \
-e ITERATIONS="1" \
-e QUERY="q1" \
-e SCALEFACTOR="1" \
-e TPCDS_HOME="/mnt/nvdl/datasets/tpcds/tpcds" \
-e RESOURCE_GPU_AMT=0.0833333 \
-e MULTI_THREADED_READ="12" \
-v /mnt/nvdl/datasets/tpcds/conf/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf \
-v /mnt/nvdl/datasets/tpcds:/data \
-v /tmp:/tmp \
--network host \
--name master \
--rm \
gcr.io/data-science-enterprise/spark-master-slurm:3.0.1
